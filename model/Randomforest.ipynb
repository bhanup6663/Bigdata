{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c4da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c4c1fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"IFD\") \\\n",
    "        .config(\"spark.some.config.option\", \"Project\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e70f643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/21 11:40:47 WARN Utils: Your hostname, Bhanus-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.168 instead (on interface en0)\n",
      "23/03/21 11:40:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/03/21 11:40:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/03/21 11:40:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark=init_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de6889d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"../dataset/vehicle_insurance_claim_fraud_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c25bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a045d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5ad764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the AgeOfPolicyHolder column into two columns, representing the minimum and maximum age values\n",
    "data = data.withColumn(\"AgeOfPolicyHolder_Min\", split(col(\"AgeOfPolicyHolder\"), \" \")[0].cast(\"int\"))\n",
    "data = data.withColumn(\"AgeOfPolicyHolder_Max\", split(col(\"AgeOfPolicyHolder\"), \" \")[2].cast(\"int\"))\n",
    "\n",
    "# Compute the average age range for each row in the AgeOfPolicyHolder column\n",
    "avg_age_range = data.select(avg((col(\"AgeOfPolicyHolder_Min\") + col(\"AgeOfPolicyHolder_Max\")) / 2)).collect()[0][0]\n",
    "\n",
    "# Add a new column that copies the Age column value when it is not 0, or the average age range otherwise\n",
    "data = data.withColumn(\"New_Age\", when(col(\"Age\") == 0, avg_age_range).otherwise(col(\"Age\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97c5cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the columns having numerical values to Double type\n",
    "numerical_cols = ['WeekOfMonth', 'WeekOfMonthClaimed', 'Age', 'New_Age', 'FraudFound_P', 'RepNumber', 'Deductible', 'DriverRating', 'Year']\n",
    "for col in numerical_cols:\n",
    "    data = data.withColumn(col, data[col].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8bfc844",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['Month', 'DayOfWeek', 'Make', 'AccidentArea', 'DayOfWeekClaimed',\n",
    "       'MonthClaimed', 'Sex', 'MaritalStatus', 'Fault', 'PolicyType',\n",
    "       'VehicleCategory', 'VehiclePrice', 'Days_Policy_Accident',\n",
    "       'Days_Policy_Claim', 'PastNumberOfClaims', 'AgeOfVehicle',\n",
    "       'AgeOfPolicyHolder', 'PoliceReportFiled', 'WitnessPresent', 'AgentType',\n",
    "       'NumberOfSuppliments', 'AddressChange_Claim', 'NumberOfCars',\n",
    "       'BasePolicy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "910555db",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [StringIndexer(inputCol=col, outputCol=col+\"_indexed\", handleInvalid=\"keep\") for col in categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCol=col+\"_indexed\", outputCol=col+\"_encoded\") for col in categorical_cols]\n",
    "pipeline = Pipeline(stages=indexers + encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8145ef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = data.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ff3553c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/21 11:43:00 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "pipelineModel = pipeline.fit(training)\n",
    "training_encoded = pipelineModel.transform(training).drop(*categorical_cols, *[\"PolicyNumber\"])\n",
    "test_encoded = pipelineModel.transform(test).drop(*categorical_cols, *[\"PolicyNumber\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0df1de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols=training_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb11ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols.remove('FraudFound_P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cf5113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8538ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\", handleInvalid=\"keep\")\n",
    "train_df = assembler.transform(training_encoded).select(\"features\", \"FraudFound_P\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69c18f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"FraudFound_P\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba17eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [50, 100]) \\\n",
    "    .addGrid(rf.maxDepth, [2, 5, 10]) \\\n",
    "    .addGrid(rf.minInstancesPerNode, [1, 5, 10]) \\\n",
    "    .addGrid(rf.minInfoGain, [0.0, 0.05]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c824ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"FraudFound_P\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97411d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec7645e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/21 12:03:21 WARN DAGScheduler: Broadcasting large task binary with size 1027.6 KiB\n",
      "23/03/21 12:03:21 WARN DAGScheduler: Broadcasting large task binary with size 1383.9 KiB\n",
      "23/03/21 12:03:22 WARN DAGScheduler: Broadcasting large task binary with size 1812.1 KiB\n",
      "23/03/21 12:03:22 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "23/03/21 12:03:23 WARN DAGScheduler: Broadcasting large task binary with size 1635.8 KiB\n",
      "23/03/21 12:03:25 WARN DAGScheduler: Broadcasting large task binary with size 1014.3 KiB\n",
      "23/03/21 12:03:25 WARN DAGScheduler: Broadcasting large task binary with size 1340.9 KiB\n",
      "23/03/21 12:03:26 WARN DAGScheduler: Broadcasting large task binary with size 1741.0 KiB\n",
      "23/03/21 12:03:26 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "23/03/21 12:03:30 WARN DAGScheduler: Broadcasting large task binary with size 1250.5 KiB\n",
      "23/03/21 12:03:30 WARN DAGScheduler: Broadcasting large task binary with size 1583.6 KiB\n",
      "23/03/21 12:03:31 WARN DAGScheduler: Broadcasting large task binary with size 1951.1 KiB\n",
      "23/03/21 12:03:47 WARN DAGScheduler: Broadcasting large task binary with size 1192.6 KiB\n",
      "23/03/21 12:03:47 WARN DAGScheduler: Broadcasting large task binary with size 1731.6 KiB\n",
      "23/03/21 12:03:48 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/03/21 12:03:49 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "23/03/21 12:03:50 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n",
      "23/03/21 12:03:52 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/03/21 12:03:54 WARN DAGScheduler: Broadcasting large task binary with size 1212.7 KiB\n",
      "23/03/21 12:03:55 WARN DAGScheduler: Broadcasting large task binary with size 1739.3 KiB\n",
      "23/03/21 12:03:56 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/03/21 12:03:57 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "23/03/21 12:03:58 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "23/03/21 12:04:00 WARN DAGScheduler: Broadcasting large task binary with size 1703.2 KiB\n",
      "23/03/21 12:04:02 WARN DAGScheduler: Broadcasting large task binary with size 1180.1 KiB\n",
      "23/03/21 12:04:03 WARN DAGScheduler: Broadcasting large task binary with size 1655.6 KiB\n",
      "23/03/21 12:04:04 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/03/21 12:04:05 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "23/03/21 12:04:06 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "23/03/21 12:04:07 WARN DAGScheduler: Broadcasting large task binary with size 1163.2 KiB\n",
      "23/03/21 12:04:19 WARN DAGScheduler: Broadcasting large task binary with size 1003.0 KiB\n",
      "23/03/21 12:04:20 WARN DAGScheduler: Broadcasting large task binary with size 1346.9 KiB\n",
      "23/03/21 12:04:20 WARN DAGScheduler: Broadcasting large task binary with size 1772.3 KiB\n",
      "23/03/21 12:04:21 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/03/21 12:04:22 WARN DAGScheduler: Broadcasting large task binary with size 1633.7 KiB\n",
      "23/03/21 12:04:24 WARN DAGScheduler: Broadcasting large task binary with size 1011.0 KiB\n",
      "23/03/21 12:04:24 WARN DAGScheduler: Broadcasting large task binary with size 1341.7 KiB\n",
      "23/03/21 12:04:25 WARN DAGScheduler: Broadcasting large task binary with size 1739.2 KiB\n",
      "23/03/21 12:04:25 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "23/03/21 12:04:26 WARN DAGScheduler: Broadcasting large task binary with size 1021.0 KiB\n",
      "23/03/21 12:04:28 WARN DAGScheduler: Broadcasting large task binary with size 1282.8 KiB\n",
      "23/03/21 12:04:29 WARN DAGScheduler: Broadcasting large task binary with size 1624.3 KiB\n",
      "23/03/21 12:04:29 WARN DAGScheduler: Broadcasting large task binary with size 1997.9 KiB\n",
      "23/03/21 12:04:45 WARN DAGScheduler: Broadcasting large task binary with size 1190.2 KiB\n",
      "23/03/21 12:04:46 WARN DAGScheduler: Broadcasting large task binary with size 1723.5 KiB\n",
      "23/03/21 12:04:47 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/03/21 12:04:48 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "23/03/21 12:04:49 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n",
      "23/03/21 12:04:50 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "23/03/21 12:04:53 WARN DAGScheduler: Broadcasting large task binary with size 1200.4 KiB\n",
      "23/03/21 12:04:53 WARN DAGScheduler: Broadcasting large task binary with size 1723.5 KiB\n",
      "23/03/21 12:04:54 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/03/21 12:04:55 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "23/03/21 12:04:56 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "23/03/21 12:04:58 WARN DAGScheduler: Broadcasting large task binary with size 1698.4 KiB\n",
      "23/03/21 12:05:00 WARN DAGScheduler: Broadcasting large task binary with size 1184.8 KiB\n",
      "23/03/21 12:05:01 WARN DAGScheduler: Broadcasting large task binary with size 1656.5 KiB\n",
      "23/03/21 12:05:02 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/03/21 12:05:03 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "23/03/21 12:05:04 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "23/03/21 12:05:05 WARN DAGScheduler: Broadcasting large task binary with size 1177.1 KiB\n",
      "23/03/21 12:05:17 WARN DAGScheduler: Broadcasting large task binary with size 1043.5 KiB\n",
      "23/03/21 12:05:18 WARN DAGScheduler: Broadcasting large task binary with size 1411.7 KiB\n",
      "23/03/21 12:05:18 WARN DAGScheduler: Broadcasting large task binary with size 1862.1 KiB\n",
      "23/03/21 12:05:19 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "23/03/21 12:05:19 WARN DAGScheduler: Broadcasting large task binary with size 1690.9 KiB\n",
      "23/03/21 12:05:22 WARN DAGScheduler: Broadcasting large task binary with size 1024.0 KiB\n",
      "23/03/21 12:05:22 WARN DAGScheduler: Broadcasting large task binary with size 1371.4 KiB\n",
      "23/03/21 12:05:22 WARN DAGScheduler: Broadcasting large task binary with size 1774.6 KiB\n",
      "23/03/21 12:05:23 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/03/21 12:05:24 WARN DAGScheduler: Broadcasting large task binary with size 1032.3 KiB\n",
      "23/03/21 12:05:26 WARN DAGScheduler: Broadcasting large task binary with size 1270.2 KiB\n",
      "23/03/21 12:05:27 WARN DAGScheduler: Broadcasting large task binary with size 1594.7 KiB\n",
      "23/03/21 12:05:27 WARN DAGScheduler: Broadcasting large task binary with size 1941.6 KiB\n",
      "23/03/21 12:05:43 WARN DAGScheduler: Broadcasting large task binary with size 1233.8 KiB\n",
      "23/03/21 12:05:44 WARN DAGScheduler: Broadcasting large task binary with size 1786.6 KiB\n",
      "23/03/21 12:05:45 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "23/03/21 12:05:46 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "23/03/21 12:05:47 WARN DAGScheduler: Broadcasting large task binary with size 4.4 MiB\n",
      "23/03/21 12:05:48 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "23/03/21 12:05:51 WARN DAGScheduler: Broadcasting large task binary with size 1226.9 KiB\n",
      "23/03/21 12:05:52 WARN DAGScheduler: Broadcasting large task binary with size 1754.0 KiB\n",
      "23/03/21 12:05:53 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/03/21 12:05:54 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "23/03/21 12:05:55 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "23/03/21 12:05:56 WARN DAGScheduler: Broadcasting large task binary with size 1717.5 KiB\n",
      "23/03/21 12:05:59 WARN DAGScheduler: Broadcasting large task binary with size 1200.6 KiB\n",
      "23/03/21 12:05:59 WARN DAGScheduler: Broadcasting large task binary with size 1683.7 KiB\n",
      "23/03/21 12:06:00 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "23/03/21 12:06:01 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "23/03/21 12:06:02 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "23/03/21 12:06:03 WARN DAGScheduler: Broadcasting large task binary with size 1155.4 KiB\n",
      "23/03/21 12:06:15 WARN DAGScheduler: Broadcasting large task binary with size 1012.2 KiB\n",
      "23/03/21 12:06:16 WARN DAGScheduler: Broadcasting large task binary with size 1365.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/21 12:06:16 WARN DAGScheduler: Broadcasting large task binary with size 1806.8 KiB\n",
      "23/03/21 12:06:17 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "23/03/21 12:06:18 WARN DAGScheduler: Broadcasting large task binary with size 1662.8 KiB\n",
      "23/03/21 12:06:20 WARN DAGScheduler: Broadcasting large task binary with size 1028.8 KiB\n",
      "23/03/21 12:06:20 WARN DAGScheduler: Broadcasting large task binary with size 1370.3 KiB\n",
      "23/03/21 12:06:21 WARN DAGScheduler: Broadcasting large task binary with size 1777.0 KiB\n",
      "23/03/21 12:06:21 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/03/21 12:06:22 WARN DAGScheduler: Broadcasting large task binary with size 1005.8 KiB\n",
      "23/03/21 12:06:24 WARN DAGScheduler: Broadcasting large task binary with size 1298.7 KiB\n",
      "23/03/21 12:06:25 WARN DAGScheduler: Broadcasting large task binary with size 1645.3 KiB\n",
      "23/03/21 12:06:26 WARN DAGScheduler: Broadcasting large task binary with size 2024.8 KiB\n",
      "23/03/21 12:06:41 WARN DAGScheduler: Broadcasting large task binary with size 1181.6 KiB\n",
      "23/03/21 12:06:42 WARN DAGScheduler: Broadcasting large task binary with size 1693.6 KiB\n",
      "23/03/21 12:06:43 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "23/03/21 12:06:44 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "23/03/21 12:06:45 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "23/03/21 12:06:46 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "23/03/21 12:06:49 WARN DAGScheduler: Broadcasting large task binary with size 1185.0 KiB\n",
      "23/03/21 12:06:49 WARN DAGScheduler: Broadcasting large task binary with size 1688.5 KiB\n",
      "23/03/21 12:06:50 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "23/03/21 12:06:51 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/03/21 12:06:52 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "23/03/21 12:06:54 WARN DAGScheduler: Broadcasting large task binary with size 1707.2 KiB\n",
      "23/03/21 12:06:56 WARN DAGScheduler: Broadcasting large task binary with size 1186.7 KiB\n",
      "23/03/21 12:06:57 WARN DAGScheduler: Broadcasting large task binary with size 1665.4 KiB\n",
      "23/03/21 12:06:58 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/03/21 12:06:59 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "23/03/21 12:07:00 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "23/03/21 12:07:01 WARN DAGScheduler: Broadcasting large task binary with size 1139.8 KiB\n",
      "23/03/21 12:07:13 WARN DAGScheduler: Broadcasting large task binary with size 1014.1 KiB\n",
      "23/03/21 12:07:13 WARN DAGScheduler: Broadcasting large task binary with size 1370.5 KiB\n",
      "23/03/21 12:07:14 WARN DAGScheduler: Broadcasting large task binary with size 1813.9 KiB\n",
      "23/03/21 12:07:14 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "23/03/21 12:07:15 WARN DAGScheduler: Broadcasting large task binary with size 1657.3 KiB\n",
      "23/03/21 12:07:17 WARN DAGScheduler: Broadcasting large task binary with size 1010.5 KiB\n",
      "23/03/21 12:07:18 WARN DAGScheduler: Broadcasting large task binary with size 1349.0 KiB\n",
      "23/03/21 12:07:18 WARN DAGScheduler: Broadcasting large task binary with size 1748.1 KiB\n",
      "23/03/21 12:07:19 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/03/21 12:07:20 WARN DAGScheduler: Broadcasting large task binary with size 1021.7 KiB\n",
      "23/03/21 12:07:22 WARN DAGScheduler: Broadcasting large task binary with size 1292.6 KiB\n",
      "23/03/21 12:07:22 WARN DAGScheduler: Broadcasting large task binary with size 1645.5 KiB\n",
      "23/03/21 12:07:23 WARN DAGScheduler: Broadcasting large task binary with size 2033.9 KiB\n",
      "23/03/21 12:07:39 WARN DAGScheduler: Broadcasting large task binary with size 1201.8 KiB\n",
      "23/03/21 12:07:39 WARN DAGScheduler: Broadcasting large task binary with size 1731.4 KiB\n",
      "23/03/21 12:07:40 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/03/21 12:07:41 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "23/03/21 12:07:42 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n",
      "23/03/21 12:07:43 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "23/03/21 12:07:46 WARN DAGScheduler: Broadcasting large task binary with size 1196.0 KiB\n",
      "23/03/21 12:07:47 WARN DAGScheduler: Broadcasting large task binary with size 1706.2 KiB\n",
      "23/03/21 12:07:48 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "23/03/21 12:07:49 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "23/03/21 12:07:50 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "23/03/21 12:07:51 WARN DAGScheduler: Broadcasting large task binary with size 1698.7 KiB\n",
      "23/03/21 12:07:54 WARN DAGScheduler: Broadcasting large task binary with size 1156.3 KiB\n",
      "23/03/21 12:07:54 WARN DAGScheduler: Broadcasting large task binary with size 1610.7 KiB\n",
      "23/03/21 12:07:55 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "23/03/21 12:07:56 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "23/03/21 12:07:57 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "23/03/21 12:07:58 WARN DAGScheduler: Broadcasting large task binary with size 1154.0 KiB\n",
      "23/03/21 12:08:02 WARN DAGScheduler: Broadcasting large task binary with size 1038.4 KiB\n",
      "23/03/21 12:08:02 WARN DAGScheduler: Broadcasting large task binary with size 1424.0 KiB\n",
      "23/03/21 12:08:03 WARN DAGScheduler: Broadcasting large task binary with size 1896.2 KiB\n",
      "23/03/21 12:08:04 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n"
     ]
    }
   ],
   "source": [
    "cvModel = cv.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1a2c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = assembler.transform(test_encoded).select(\"features\", \"FraudFound_P\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52855d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/21 12:08:21 WARN DAGScheduler: Broadcasting large task binary with size 1703.5 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9425621168118749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/21 12:08:22 WARN DAGScheduler: Broadcasting large task binary with size 1703.5 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9457671957671958\n"
     ]
    }
   ],
   "source": [
    "print(evaluator.evaluate(cvModel.transform(train_df)))\n",
    "print(evaluator.evaluate(cvModel.transform(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "85bd705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=cvModel.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32848abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import  MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "57032b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/21 12:08:28 WARN DAGScheduler: Broadcasting large task binary with size 1703.5 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.94871033934568\n"
     ]
    }
   ],
   "source": [
    "evaluator.setMetricName('weightedPrecision')\n",
    "precision = evaluator.evaluate(prediction)\n",
    "print(\"Precision = %s\" % precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7c983287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/21 12:08:32 WARN DAGScheduler: Broadcasting large task binary with size 1703.5 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall = 0.9457671957671958\n"
     ]
    }
   ],
   "source": [
    "evaluator.setMetricName('weightedRecall')\n",
    "recall = evaluator.evaluate(prediction)\n",
    "print(\"Recall = %s\" % recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c94e945f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/21 12:08:33 WARN DAGScheduler: Broadcasting large task binary with size 1703.5 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.9200527300867437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/03/21 17:14:39 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 414729 ms exceeds timeout 120000 ms\n",
      "23/03/21 17:14:39 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "evaluator.setMetricName('f1')\n",
    "f1_score = evaluator.evaluate(prediction)\n",
    "print(\"F1 Score = %s\" % f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb92589d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
